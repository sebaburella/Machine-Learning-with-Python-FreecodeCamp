{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8RZOuS9LWQvv"},"outputs":[],"source":["# import libraries\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  !pip install tf-nightly\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import pandas as pd\n","from tensorflow import keras\n","!pip install tensorflow-datasets\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# helps in text preprocessing\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMHwYXHXCar3"},"outputs":[],"source":["# get data files\n","!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n","!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n","\n","train_file_path = \"train-data.tsv\"\n","test_file_path = \"valid-data.tsv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_h508FEClxO"},"outputs":[],"source":["train_file = pd.read_table(train_file_path, header=None)\n","test_file = pd.read_table(test_file_path, header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOMKywn4zReN"},"outputs":[],"source":["X_train = train_file[1]\n","Y_train = np.array(train_file[0].to_list())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbKt3uZMnfd9"},"outputs":[],"source":["X_test = test_file[1]\n","Y_test = np.array(test_file[0].to_list())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZdT2FjXniVD"},"outputs":[],"source":["vocab_size = 10000\n","embedding_dim = 16\n","max_length = 100\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"\"\n","training_size = 20000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9tD9yACG6M9"},"outputs":[],"source":["t = Tokenizer(vocab_size,oov_token=oov_tok)\n","t.fit_on_texts(X_train)\n","\n","word_index = t.word_index\n","\n","X_train_t = t.texts_to_sequences(X_train)\n","training_padded = pad_sequences(X_train_t, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","X_test_t = t.texts_to_sequences(X_test)\n","testing_padded = pad_sequences(X_test_t, maxlen=max_length, padding=padding_type, truncating=trunc_type)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72vSU-lAorGC"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","train_y = le.fit_transform(Y_train)\n","test_y = le.transform(Y_test)\n","\n","training_padded = np.array(training_padded)\n","train_label = np.array(train_y)\n","testing_padded = np.array(testing_padded)\n","test_label = np.array(test_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_okxD8Vot3V"},"outputs":[],"source":["model = keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","num_epochs = 5\n","history = model.fit(training_padded, train_label, epochs=num_epochs, validation_data=(testing_padded, test_label))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNCcFUcLqwS-"},"outputs":[],"source":["def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","  \n","plot_graphs(history, \"accuracy\")\n","plot_graphs(history, \"loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4oIOFPbqyg0"},"outputs":[],"source":["sentence = [\"sale today! to stop texts call 98912460324\"]\n","\n","def previsao(sentence):\n","  sequences = t.texts_to_sequences(sentence)\n","  padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","  return (float(model.predict(padded)), 'ham' if model.predict(padded) < 0.5 else 'spam' )\n","\n","previsao(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QzQcJ6-nq292"},"outputs":[],"source":["def predict_message(sentence):\n","  sequences = t.texts_to_sequences([sentence])\n","  padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","  return (float(model.predict(padded)), 'ham' if model.predict(padded) < 0.5 else 'spam' )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSRWiaNHq6Nm"},"outputs":[],"source":["def test_predictions():\n","  test_messages = [\"how are you doing today\",\n","                   \"sale today! to stop texts call 98912460324\",\n","                   \"i dont want to go. can we try it a different day? available sat\",\n","                   \"our new mobile video service is live. just install on your phone to start watching.\",\n","                   \"you have won Â£1000 cash! call to claim your prize.\",\n","                   \"i'll bring it tomorrow. don't forget the milk.\",\n","                   \"wow, is your arm alright. that happened to me one time too\"\n","                  ]\n","\n","  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n","  passed = True\n","\n","  for msg, ans in zip(test_messages, test_answers):   \n","    prediction = predict_message(msg)\n","    if prediction[1] != ans:\n","      passed = False\n","\n","  if passed:\n","    print(\"You passed the challenge. Great job!\")\n","  else:\n","    print(\"You haven't passed yet. Keep trying.\")\n","\n","test_predictions()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xST3zcPrq7k-"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"fcc_sms_text_classification.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/freeCodeCamp/boilerplate-neural-network-sms-text-classifier/blob/master/fcc_sms_text_classification.ipynb","timestamp":1667112885580}]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.4"},"vscode":{"interpreter":{"hash":"0f17dde64770433992390f8473ebad215aa284b6908de17513dd447e079dff6d"}}},"nbformat":4,"nbformat_minor":0}
